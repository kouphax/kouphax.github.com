<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom"><id>urn:yobriefca-se:feed:agile</id><updated>Sun Jan 05 00:00:00 UTC 2014</updated><title type="text">Yo! Briefcase: agile</title><link rel="self" href="https://yobriefca.se/feed/agile.xml"></link><entry><title>Continuous Delivery &amp; Boy Scouting Your Deployment Pipeline</title><updated>Sun Jan 05 00:00:00 UTC 2014</updated><author><name>James Hughes</name></author><link href="https://yobriefca.se/blog/2014/01/05/continuous-delivery-and-boy-scouting-your-deployment-pipeline/"></link><id>urn:yobriefca-se:feed:post:Continuous Delivery &amp; Boy Scouting Your Deployment Pipeline</id><content type="html">&lt;p&gt;Talking to teams and stakeholders within organisations over the last few years I've seen very strong concerns that &lt;a href="http://en.wikipedia.org/wiki/Continuous_delivery"&gt;continuous delivery&lt;/a&gt; was not for them. Usually it was because there was already a process in place - a process that involved lead times in the weeks or months, a lot of repeated manual work and many phases of QA prior to any release being deployed by some third party vendor. They worry, especially, that they would have very little chance of automating everything in the process.&lt;/p&gt;&lt;h2&gt;Throwing the baby out with the bath water&lt;/h2&gt;&lt;p&gt;The goal of continuous delivery isn't actually about automating everything (it just so happens that in many cases automation has significant benefits). Continuous delivery is about reducing the time to deliver a single change to production so to establish a tighter feedback loop between your company or product and your users. &lt;/p&gt;&lt;p&gt;However a lot of the time taken to deploy a release may well be out of your control, usually for the reasons quoted above. The thing is though, things change. It takes time but things always change. To quote Dr. Ian Malcolm - "&lt;a href="http://www.youtube.com/watch?v=SkWeMvrNiOM"&gt;Life finds a way&lt;/a&gt;". For example - your QA department might well suddenly discover the joys of automating a lot of their manual regression tests, your service management contract may expire and some new executive might suggest you try this new fangled "agile cloud as a service stuff" on the back of promises like 10x productivity&lt;a name="_1"&gt;&lt;/a&gt;&lt;a href="#1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. There are lots of reasons, and most of them a blessing in disguise even if they are a bit ill-informed. &lt;strong&gt;Being ready allows you to capitalise on this organistational change&lt;/strong&gt; and make it last.&lt;/p&gt;&lt;h2&gt;Visualise your Pipeline&lt;/h2&gt;&lt;p&gt;Draw a diagram or outline the steps that a change or single commit goes through to get onto a production box. This isn't done enough in projects, there are fragments of it in peoples heads and there are foggy areas of uncertainty. Drawing a pipeline, one that covers multiple deparments is actually quite an eye opener. &lt;/p&gt;&lt;p&gt;Another thing that this task does is help you realise that deployment isn't a single big black box that is always as slow as the slowest step. Its a series of steps and by visualising it you can simulate changes to it. That 1/2 day it takes to deploy to a preview environment for developer sanity checking may pale in comparison to the 4 week period that you wait to see if the production deployment was successful but bringing that 1/2 day down to 10 minutes for a team of, say, 6 developers has a more long term benefit. Even more, if you get to extend the process for deploying to preview into the QA environments at a later date - the work is mostly already done&lt;a name="_2"&gt;&lt;/a&gt;&lt;a href="#2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;So you may not have hugely reduced the time to a &lt;strong&gt;production&lt;/strong&gt; release but you've helped tighten up the development feedback and prepared yourself for a future where these changes can be reused further down the pipeline.&lt;/p&gt;&lt;h2&gt;Boy Scouting&lt;/h2&gt;&lt;p&gt;But a lot of this work is far from trivial and right now it might be hard to sell it to the people holding the purse strings and Gantt charts so what can you do? Well, a few years ago Robert C. Martin (Uncle Bob) suggested that you can &lt;a href="http://programmer.97things.oreilly.com/wiki/index.php/The_Boy_Scout_Rule"&gt;apply the Boy Scout rule to code bases&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The Boy Scouts have a rule: "Always leave the campground cleaner than you found it." If you find a mess on the ground, you clean it up regardless of who might have made the mess. You intentionally improve the environment for the next group of campers.&lt;/p&gt;
&lt;/blockquote&gt;&lt;p&gt;Applying this rule to a code base means that every check in you should, &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;tidy up a little bit of extra code,&lt;/li&gt;
  &lt;li&gt;add another useful unit test,&lt;/li&gt;
  &lt;li&gt;refactor a tiny bit of code, or,&lt;/li&gt;
  &lt;li&gt;tidy up a bit of formatting&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Anything to have a positive impact on the quality of code in the project. &lt;/p&gt;&lt;p&gt;I proffer that &lt;strong&gt;the same rule can be applied to your deployment pipeline&lt;/strong&gt;. Things like - introduce a script that starts up a simple vagrant environment, add a little bit of Puppet/Chef/Salt to create a production-like environment on developers machines, automate that file copy/paste process that Steve in Team B does during every release with a script, document the deployment process, publish the deployment pipeline, add a bit more validation to your CI server. Anything that makes the pipeline that tiny bit less painful to flow through.&lt;/p&gt;&lt;p&gt;In time these small incremental changes have a compound positive effect that results in fewer issues with deployment (and on-boarding) and acts as an example to people involved downstream in the deployment pipeline. &lt;/p&gt;&lt;p&gt;Ultimately the technical change required to move towards continuous delivery takes time and effort but it is nothing compared to the cultural and organisational changes. Proactively addressing the technical changes that can be made now can benefit your current process and also prepare you for a more effective delivery model in the future.&lt;/p&gt;
&lt;hr /&gt;&lt;p&gt;&lt;sup&gt;&lt;a name="1"&gt;&lt;/a&gt;&lt;a href="#_1"&gt;1&lt;/a&gt;: Both of these things have happened in recent years to projects I've been involved in.&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;sup&gt;&lt;a name="2"&gt;&lt;/a&gt;&lt;a href="#_2"&gt;2&lt;/a&gt;: We haven't even pointed out that this developer deployment is going to be of immediate benefit for on-boarding new team members as well.&lt;/sup&gt;&lt;/p&gt;</content></entry><entry><title>Better Management Through Agile Teams</title><updated>Thu Oct 17 23:00:00 UTC 2013</updated><author><name>James Hughes</name></author><link href="https://yobriefca.se/blog/2013/10/17/better-management-through-agile-teams/"></link><id>urn:yobriefca-se:feed:post:Better Management Through Agile Teams</id><content type="html">&lt;p&gt;Wait is waste! Value stream mapping, as &lt;a href="http://en.wikipedia.org/wiki/Value_stream_mapping"&gt;Wikipedia reads&lt;/a&gt;, is a lean manufacturing technique used to analyse and design the flow of materials and information required to bring a product or service to a consumer.&lt;/p&gt;&lt;p&gt;The process of visualising a value stream is valuable for many reasons, one of which is that it can highlight bottlenecks or wait states. A wait state is a period of time in which actors in the value stream are waiting for something to happen, e.g. waiting for another dependent actor to finish their task. Actors in a wait state are typically not being utilised and therefore wasting time and money. Visualising the stream and quantifying the cost of these wait periods can often lead to fundamental organisational change.&lt;/p&gt;&lt;p&gt;In plan based or waterfall delivery wait states are ever present, at least from a single project perspective. All phases have a certain lead time while actors (analysts, developers, ops, testers etc.) start work and feed back more work to the other actors. The larger the phases, the longer that lead time is (within limits of course). Developers develop while testers wait, Testers test while developers wait. So how do you deal with these wait states? Typically speaking a customer isn't going to be to fond of paying for people to twiddle their thumbs. Depending on the period of time the wait state is expected to last you're either going to have to take the hit or repurpose the actors elsewhere. Repurposing is a very common practise - you'll see analysts swoop in at the start of a project write up a big document and slingshot onto the next project, resourcing has be carefully orchestrated so that a developer can roll off one project onto another that is about to start development and of course this all requires that the project goes according to plan - its like a giant game of Jenga. In the middle of a riot.&lt;/p&gt;&lt;p&gt;These practises may help reduce &lt;strong&gt;visible&lt;/strong&gt; wait states but fail totally at solving the root problem - you've simply diverted peoples attention. You've traded off the &lt;strong&gt;measurable&lt;/strong&gt; for the &lt;strong&gt;unmeasuarable&lt;/strong&gt;. You've lost valuable insight by losing your analysts, increased the time taken to deliver features to due ramp up time for new developers and reduced effectiveness of testing because all the testers usually have to go on are out of date documents. Its hard to make a change when you don't realise doing it badly. The other glaring issue here is that the practitioners aren't the ones covering the cost of these problems - its the customer.&lt;/p&gt;&lt;p&gt;So what of agile &amp;amp; lean? The agile/lean model actually tends toward reducing wait states naturally. The model promotes 2 things&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;an "everybody, all at once, from early on" (&lt;a href="http://www.amazon.com/Lean-Architecture-Agile-Software-Development/dp/0470684208"&gt;Lean Architecture&lt;/a&gt;) mentality. This is realised in the form of a team being the primary unit of delivery as opposed to a specialist with the support of a team.&lt;/li&gt;
  &lt;li&gt;Delivery in small batch sizes. Deliver in smaller increments reduces lead time between deliverables. In fact any large constraints that can potentially create lag become immediately apparent and &lt;strong&gt;need&lt;/strong&gt; to be dealt with to facilitate quick return.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The &lt;strong&gt;team&lt;/strong&gt; analyses, the &lt;strong&gt;team&lt;/strong&gt; develops, the &lt;strong&gt;team&lt;/strong&gt; tests, the &lt;strong&gt;team&lt;/strong&gt; deploys, the &lt;strong&gt;team&lt;/strong&gt; doesn't need to wait. Start to finish the people that know the most deliver the solution and they do so by delivering small chunks of features to the customer to support continuous and evolving understanding of the solution. This reduces any potential bottlenecks from knowledge loss or misinterpretation of what the end user wants.&lt;/p&gt;&lt;p&gt;If you're coming from an organisation that is used to cycling siloed roles and specialists (analysts, developers, testers) the transition to a more team focused cross functional model isn't an easy one but the result is a more effective, predictable approach to delivery which benefits both yourself and the customer.&lt;/p&gt;</content></entry><entry><title>Disciplined Agile Delivery</title><updated>Mon May 27 23:00:00 UTC 2013</updated><author><name>James Hughes</name></author><link href="https://yobriefca.se/blog/2013/05/27/disciplined-agile-delivery/"></link><id>urn:yobriefca-se:feed:post:Disciplined Agile Delivery</id><content type="html">&lt;p&gt;Thanks to &lt;a href="http://www.liberty-it.co.uk/"&gt;Liberty&lt;/a&gt; I had the opportunity to attend a morning session by &lt;a href="http://www.ambysoft.com/"&gt;Scott Ambler&lt;/a&gt; around &lt;a href="http://www.disciplinedagiledelivery.com/"&gt;Disciplined Agile Delivery&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;The selling point around DAD seems to be that it offers a more complete view of both project and organisational delivery than what Scrum does. The argument being that Scrum gives you a framework within which you can execute project delivery through sprints but doesn't itself address what happens before (where did the product backlog come from) or after (how are we actually releasing the product to production). So Scrum teams start adopting other practises to roll their own, more complete, process. Of course this sort of approach should really be done by "Process Experts" and as most people are not "Process Experts" the resulting process is typically sub-optimised. DAD suggests that rather than starting at the baseline and optimising to the middle, why not just start at the middle?&lt;/p&gt;&lt;p&gt;This is somewhat analogous to the old libraries vs frameworks debate in the technical world. Frameworks make decisions for you and as such are great when venturing into a new technology space but as you become an "expert" in that area the helpfulness of frameworks diminishes and they can become rather restrictive. At this point "experts" begin to craft their own solutions typically utilising a small number of libraries. I like to consider my self well versed in development of solutions and as such I typically avoid big frameworks and favour smaller, more lean bespoke development.&lt;/p&gt;&lt;p&gt;In this sense DAD is a framework, it gives you everything, and in comparison Scrum could be considered a library, giving you a small set of tools and as such I'm inclined to tend toward rolling my own process utilising various methodologies and processes. This has worked for my projects.&lt;/p&gt;&lt;p&gt;But here's the rub - While I may be a "technical expert" (tending toward the use of libraries over frameworks) I am by no means a "Process Expert". My current experiences have been with smaller scale projects and a bespoke process will fit well at that scale without much expert knowledge. We do, however, need to move beyond that; toward proper organisational change and without "Process Experts" the approach of mashing some principles and methodologies together will result in a sub-optimised process tending toward failure.&lt;/p&gt;&lt;p&gt;The process aspect of large scale software delivery is my "new technology space" and as such it may be prudent to investigate a large focused framework until such times as we can adapt and move beyond its limitations. Will it be DAD? Will it be the Scaled Agile Framework? Perhaps it will be like the carefully governed but organically grown Spotify style model. I don't know yet, but I do know its time to start moving toward using agile in the large and I doubt a slapdash approach will be enough until I developed a broader understanding into larger organisational challenges.&lt;/p&gt;</content></entry><entry><title>The Old "Agile is for Developers" Myth</title><updated>Tue May 07 23:00:00 UTC 2013</updated><author><name>James Hughes</name></author><link href="https://yobriefca.se/blog/2013/05/07/the-old-agile-is-for-developers-myth/"></link><id>urn:yobriefca-se:feed:post:The Old "Agile is for Developers" Myth</id><content type="html">&lt;p&gt;There is a common misconception among people who are just starting out on the agile path that the agile model favors developers and downplays other roles. While it is true that agile puts a greater focus and added responsibility on developers it also broadens the definition of developer from the niche of "people who write code" role to a more umbrella term of "people who deliver software".&lt;/p&gt;&lt;p&gt;Another comment I heard being made, admittedly in jest, is that agile is "Disneyland for Developers" and honestly this couldn't be further from the truth. In fact agile methods typically expect people involved in delivery to be MORE responsible for delivery. Developers are no longer just mindless code monkeys banging out tasks against pseudo-code written in a document. No, developers are expected to &lt;strong&gt;DEVELOP a working solution&lt;/strong&gt;. This includes analysis, design, architecture, development &amp;amp; testing. All of this is expected to be done with one eye on the "big picture", they are expected to understand WHY they are doing something from, both, a technical and business perspective, they are expected to be at least understand how their code is deployed and often expected to be able to deploy it. You don't have &lt;em&gt;the Java guys&lt;/em&gt;, &lt;em&gt;the Web guys&lt;/em&gt; or &lt;em&gt;the DBAs&lt;/em&gt; - no, a single person in a team should at least be capable of driving out a vertical slice of functionality from infrastructure to database to services to HTML and JavaScript. Of course the slice doesn't have to be, nor will be, perfect right now. There will always be space for specialists to come in and make their areas better, more secure, faster, whatever needs done. But at the very least when all but one person on the team catches some rare exotic disease on a team bonding night out that person can still deliver &lt;strong&gt;valuable&lt;/strong&gt; working software until the rest of the team recovers.&lt;/p&gt;&lt;p&gt;Ultimately though the agile methods that are technically focused are about ensuring quality of delivery. Delivered features should be &lt;strong&gt;"done"&lt;/strong&gt; rather than thrown together an handed over a test team to let them find the issues - a common side effect of time constrained, fixed scope, phased delivery. That practice is unacceptable even in plan based or phased models and regardless of the project approach a development team can and should be making use of practices often associated with agile.&lt;/p&gt;&lt;p&gt;But other roles necessary in the delivery of a project also benefit greatly from agile approaches. Just think of some of the things these other roles would do within more traditional project delivery models,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Who has to spend days or even weeks manually running the same few hundred scripted tests every few months to avoid regressions and assert correctness of the system?&lt;/em&gt; Not the developers thats for sure. Testers are often required to execute manual scripted tests which are slow, prone to error and have a relatively low ROI compared to other testing techniques. Manual tests check for issues you know will break your system, but its the unknown issues that typically kill your solution. Automation of these tests (by developers and testers) gives faster more frequent feedback and allows testers to actually do interesting, rewarding, more valuable testing such as Exploratory Testing. Testers should not be there to break things but to ensure we build the right thing right in the first place.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Who spends weeks going through multiple versions of documents that seldom get updated and go out of date shortly after sign off?&lt;/em&gt; Again, not typically the developers. Business Analysts and Solution Architects spend a long time producing documents that create a contract for all parties involved. Often, though, they are only pulled out during "disputes" around agreed functionality (between either developers &amp;amp; tester or customers &amp;amp; analysts). If that happens though, then who is actually reading these things properly? No matter how rigorous you make documents there will always be the problem of interpretation. You can't misinterpret a running solution.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Who is expected to "manage expectations" when delivery is slipping beyond the scheduled dates?&lt;/em&gt;. Long running projects that pin all their plans on up front estimates will slip. It's inevitable unless you've managed to overestimate everything but then I'd wonder why you are doing the work and not your more aggressive competitor. When this happens it's typically the job of the manager and senior technical folks to inform the customer in the best way possible, to "manage their expectations" (shudder). No one wants to do that. In typical agile models visibility is a key differentiator (another way to ensure quick and frequent feedback) which removes the need to for big bang disappointment. When things change or slip you know about them much quicker and can course adjust, the impact is significantly reduced.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;All these (arguably wasteful) practices are typically the responsibility of people in non-developer roles. Now that we have reduced or removed these practices does that mean we've made the roles redundant? Not at all - as with the developer role increasing in scope so does the manager, analyst and tester. Testers no longer just "test", they have a more important function - assuring that what they test is the right thing, they've become crucial to analysis. Analysts also need to understand aspects of project management and managers themselves can move to a more hands-off sales and account management role as delivery is managed by the team itself. What we will see is a reduction of specific titles on projects, most people no longer fit those niche titles.&lt;/p&gt;&lt;h2&gt;Facilitators &amp;amp; Implementors&lt;/h2&gt;&lt;p&gt;So, yes, agile approaches certainly favour working software over volumes of documentation describing what the system &lt;strong&gt;should&lt;/strong&gt; do but heck - so does common sense. &lt;/p&gt;&lt;p&gt;Agile approaches flatten the role structure across the delivery of a project. You end up with umbrella terms like facilitators (who ensure the right thing is being built) and implementors (who ensure the thing is being built right). &lt;/p&gt;&lt;p&gt;You go from this,&lt;/p&gt;&lt;p&gt;&lt;img src="/images/blog/traditional-view.png" alt="Traditional View" _="_" /&gt;&lt;/p&gt;&lt;p&gt;To something more like this,&lt;/p&gt;&lt;p&gt;&lt;img src="/images/blog/agile-view.png" alt="High-level Agile View" _="_" /&gt;&lt;/p&gt;&lt;p&gt;If you wanted to map these intentionally nebulous terms back to typical roles in a more traditional model you have,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Facilitators&lt;/strong&gt; - Business Analysts, Solution Architects, Customers, Stakeholders, Users, Testers, Project Managers, Legal etc.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Implementors&lt;/strong&gt; - Developers, Testers, DBAs, Designers&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Its clear to see where the commonplace agile roles fall as well - Product Owner and Scrum Master would be &lt;strong&gt;facilitators&lt;/strong&gt; and the team would be the &lt;strong&gt;implementors&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;Already, even at this high level you're getting overlaps and in many ways everyone plays their part as both a &lt;strong&gt;facilitator&lt;/strong&gt; and an &lt;strong&gt;implementor&lt;/strong&gt; but its generally obvious what a persons primary function is and you can plan around that accordingly.&lt;/p&gt;&lt;p&gt;You don't need fancy, lofty titles because you have a single purpose. Titles only force attribution of responsibility to particular people, they enforce specialism and defensive attitudes. Titles shouldn't affect the delivery of a solution.&lt;/p&gt;&lt;p&gt;So, no, "agile" is not just for developers, it's for the facilitators, the stakeholder &amp;amp; the implementors, it's an all-encompassing first step on the road to refocusing our goals from following a process to delivering the right thing quickly and painlessly.&lt;/p&gt;</content></entry><entry><title>Hardening Sprints: Just Say No?</title><updated>Wed Apr 17 23:00:00 UTC 2013</updated><author><name>James Hughes</name></author><link href="https://yobriefca.se/blog/2013/04/17/hardening-sprints-just-say-no/"></link><id>urn:yobriefca-se:feed:post:Hardening Sprints: Just Say No?</id><content type="html">&lt;p&gt;I was recently asked by a PM in my company if "hardening sprints" are allowed in agile projects and I gave the very pragmatic answer of "you do what needs to be done". I left the conversation not feeling right though and I've been thinking about the question ever since. To be honest my gut instinct is that, with certain exceptions, these sort of sprints are a smell and their origins are firmly rooted in phased/waterfall delivery. I'll address the &lt;em&gt;"with certain exceptions"&lt;/em&gt; caveat a bit later but lets first dive into the idea of hardening sprints.&lt;/p&gt;&lt;h2&gt;What is a hardening sprint?&lt;/h2&gt;&lt;p&gt;&lt;img src="/images/blog/hardening-sprints.png" alt="We'll Just Squeeze the other bricks in when we're done with the house" _="_" /&gt;&lt;/p&gt;&lt;p&gt;A hardening sprint is a timebox or sprint reserved at the end of a group of sprints (usually prior to release) to allow testing or hardening of the release. This could mean extra testing, different types of testing, refactoring, reviews etc. It brings with it the rather bizarre concept of "Done Done" - i.e. features that have been delivered in previous sprints may be "Done" but not "Done Done". So it may be coded and "kind-of" working and "kind-of" tested and people are "kind-of" happy with it and yeah its "kind-of" done but we'll wait until the end to know if we are really done.&lt;/p&gt;&lt;h2&gt;So What?&lt;/h2&gt;&lt;p&gt;It strikes me as "kind-of" odd that this sort of thing happens without people raising an eyebrow. For one thing there is no such thing as "Done Done" and if we don't admit it I fear that we'll see "Done Done Done" pushing its way into our process vocabulary. &lt;/p&gt;&lt;p&gt;The next thing that strikes me - there is absolutely no data available to predict how long this "hardening" process should take. If we take it at face value the term implies a single sprint. How can we be sure whatever unpredicatable stuff comes up during that sprint can actually be addressed and adequatley resolved in that sprint? Or, taking it to the other extreme (indefinite amount of sprints) how do we know when to stop - afterall nothing is ever perfect.&lt;/p&gt;&lt;h2&gt;Undoing All The Good Work?&lt;/h2&gt;&lt;p&gt;So we've spent X amount of sprints refining our approach to delivery, continually improving and learning and now we've thrown the project into this huge dark pit of uncertainty and "hardening". Surely I'm not alone in thinking this sounds somewhat wrong.&lt;/p&gt;&lt;p&gt;Another risk is that this kind of strucutre will create is a potential reduction in ongoing quality. It could be argued that hardening sprints, much like the old phased/waterfall approach to delivery, removes a certain amount of responsibility from the delivery team. Now there is less of a desire for developers to apply as much rigour to their code as they may have - afterall &lt;em&gt;"the testers will find the bugs so why waste my time being thorough?"&lt;/em&gt;. But if you are deferring your user or penetration testing a few months down the line there is always this notion that the team can just &lt;em&gt;"throw it in and see what comes out in the wash"&lt;/em&gt;. &lt;/p&gt;&lt;h2&gt;"With Certain Exceptions"&lt;/h2&gt;&lt;p&gt;Of course, like every rule, there may be exceptions. One obvious exception is external penetration testing. There can be considerable cost and time assoicated with getting a third party specialist in and its certainly not viable to do it every sprint. So defering a full pen testing cycle until near the release is an acceptable and often necessary exception. But that doesn't mean the team should throw all care about security out the window - the goal of the penetration testing should be to validate that there are no vulnerabilities not to discover them.&lt;/p&gt;&lt;h2&gt;Next Time Gadget... Next Time&lt;/h2&gt;&lt;p&gt;So are "hardening sprints" a good idea? I'm inclined, as negative as it may be, to start with "no" and take it from there, afterall its better to start with discovering &lt;strong&gt;why we can't&lt;/strong&gt; do certain things inside of a sprint rather than assume &lt;strong&gt;we can't&lt;/strong&gt; and carry on ignorant of the potential benefits.&lt;/p&gt;</content></entry><entry><title>Teams or People?</title><updated>Sun Apr 07 23:00:00 UTC 2013</updated><author><name>James Hughes</name></author><link href="https://yobriefca.se/blog/2013/04/07/teams-or-people/"></link><id>urn:yobriefca-se:feed:post:Teams or People?</id><content type="html">&lt;p&gt;A team is much more than a group of people thrown together for the period of a project. This is quite common in a utilisation based business model where downtime is viewed, on the balance sheets at least, as money wasted. I'd call that myopic. &lt;/p&gt;&lt;p&gt;Putting aside other arguments for a moment (downtime is quite often good for allowing motivated people to learn and grow) lets think about &lt;a href="http://en.wikipedia.org/wiki/Tuckman%27s_stages_of_group_development"&gt;Tuckman's Stages of Group Development&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;img src="/images/blog/tuckmans.png" alt="Half Baked Tuckmans Model" _="_" /&gt;&lt;/p&gt;&lt;p&gt;Tuckmans model suggests that teams go through various stages of development, as denoted above. During these phases various things happen,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Forming&lt;/strong&gt; - the team comes together shares their history and begins to develop an understanding of the problem to be solved.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Storming&lt;/strong&gt; - after the gentle introduction people begin finding their place in the team. Dominant parties fight for control, less dominant sniff out their leaders and the power struggle kicks off.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Norming&lt;/strong&gt; - the power struggle is over and people understand their place in the team. Less impediments occur through communication.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Performing&lt;/strong&gt; - the team has gelled and is working effectively, everyone is in the role they need to be and everyone trusts each other.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;There is a final stage - &lt;strong&gt;Adjourning&lt;/strong&gt; where the team, as a collective whole, part ways - but I'll get to that later.&lt;/p&gt;&lt;p&gt;What does the y-axis in this pseudo-graph represent? I guess the obvious answer is team productivity but given the many factors that can affect team productivity/efficacy this isn't a realistic metric. No, the y-axis in this case reflects the teams &lt;strong&gt;focus on their goal&lt;/strong&gt; of delivering the solution. In this situation it makes sense that a "team" become a staple unit of delivery vs the old resource rumble of "whoever is free". Short-lived teams of randomly selected individuals are always going to be operating at sub-optimal levels due to the very nature of team dynamics. Now here's the rub - more often than not this performance is nigh on impossible to quantify. In fact if "people as units of delivery" has been a thing for a while you'll find people making excuses for inefficiencies by front-loading of estimates. What happens then in sales and bids, how can a company who's estimates are derived due to sub-optimal team output remain competitive but keep their process the same? One dubious tactic would be for sales team gently massaging numbers and rates to make them more appealing. This makes the entire delivery process from sales to final delivery of a solution highly inefficient and pressured and we haven't even touched on the evils of potential overselling and micromanaging!&lt;/p&gt;&lt;p&gt;So - the &lt;strong&gt;team a a unit of delivery&lt;/strong&gt; makes sense IMHO, but it's not without it's problems. Moving to a team-based model requires a significant jump in company culture, accounting, sales and, if you'll let me use the word, resourcing. There are potentially huge visible risks in long stretches of downtime for teams. Arguably though large visible, almost predictable risks, are significantly better than unquantifiable consistent loses right? At least you can mitigate them.&lt;/p&gt;&lt;h2&gt;Adjourning&lt;/h2&gt;&lt;p&gt;A team can't stay a team forever. People &lt;a href="http://en.wikipedia.org/wiki/Bus_factor"&gt;get hit buses&lt;/a&gt; or worse get bored and a long lived team that refuses to change is simply another silo of knowledge that methodologies like agile try and crack open.&lt;/p&gt;&lt;p&gt;But &lt;strong&gt;adjouring&lt;/strong&gt; the team isn't about throwing the core team to the wind. Too much team churn and you end up back a square one. Too little team churn and you've got the silo problem. Team members should be rotated to allow knowledge to propagate (inwards and outwards from the original teams perspective). However this clearly brings its own problems (is a person who's constantly rotated really ever part of a team) and the balance needs to be struck over time. &lt;/p&gt;&lt;p&gt;Spotify is decent example for this sort of cross-team knowledge sharing and I'd recommend checking out &lt;a href="https://dl.dropbox.com/u/1018963/Articles/SpotifyScaling.pdf"&gt;Scaling Agile @ Spotify&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;The team as a unit of delivery&lt;/em&gt; is certainly more suited to product based companies or large, long running projects because it feels more natural. In a services based outfit or consultancy house being able to ship people about at will is &lt;em&gt;easier&lt;/em&gt; but thats not to say its actually beneficial. While it brings its own unique challenges team-based resourcing can allow organisations and project to greater realise their true potential.&lt;/p&gt;</content></entry><entry><title>Trello Cards: Materialising Trello Boards</title><updated>Fri Dec 28 00:00:00 UTC 2012</updated><author><name>James Hughes</name></author><link href="https://yobriefca.se/blog/2012/12/28/trello-cards-materialising-trello-boards/"></link><id>urn:yobriefca-se:feed:post:Trello Cards: Materialising Trello Boards</id><content type="html">&lt;blockquote&gt;&lt;p&gt;TL;DR I ported &lt;a href="https://github.com/psd/pivotal-cards"&gt;pivotal-cards&lt;/a&gt; to &lt;a href="http://yobriefca.se/trello-cards"&gt;trello-cards&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;&lt;p&gt;I recently did a spot of work with the awesome and brilliant people of the &lt;a href="http://digital.cabinetoffice.gov.uk/category/gds/"&gt;Government Digital Service&lt;/a&gt; and being big fans of getting stuff done they make use of whiteboards and index cards to visualise the flow of work on the various projects. Thats all well and good but it makes reporting to senior managers, stakeholders and remote people a bit difficult (and for the uber paranoid - what about auditing!!!). To that end this flow of work was also mirrored online - and in GDS's case the tool of choice was usually &lt;a href="http://pivotaltracker.com"&gt;Pivotal Tracker&lt;/a&gt;. In order to bridge the gap between the online and "real" one of the smart chaps at GDS wrote &lt;a href="https://github.com/psd/pivotal-cards"&gt;pivotal-cards&lt;/a&gt; which lets you generate printable index cards from you pivotal board. Lovely stuff&lt;/p&gt;&lt;p&gt;&lt;a href="http://www.flickr.com/photos/psd/7160723862/" title="Pivotal Cards by psd, on Flickr"&gt;&lt;img src="http://farm8.staticflickr.com/7223/7160723862_ef5d8e59a7.jpg" width="500" height="442" alt="Pivotal Cards" /&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Anyway - I spent some time today porting this little project to Trello. I have been using Trello more and more on recent projects but always miss the physicality of real index cards and I'm usually strapped for time to start writing them out myself.&lt;/p&gt;&lt;p&gt;So here it is - &lt;a href="http://yobriefca.se/trello-cards"&gt;trello-cards&lt;/a&gt;, I've tried to keep it pretty much 1:1 with pivotal-cards but there are some &lt;code&gt;TODO&lt;/code&gt;s still outstanding - the current card make up looks a bit like this.&lt;/p&gt;&lt;p&gt;&lt;img src="/images/blog/cardmocks.png" /&gt;&lt;/p&gt;&lt;p&gt;So basically follow the instructions on the &lt;a href="http://yobriefca.se/trello-cards/"&gt;project page&lt;/a&gt; and hopefully it should all work out. If it doesn't - &lt;a href="https://github.com/kouphax/trello-cards"&gt;FORK IT 'N FIX IT&lt;/a&gt; or &lt;a href="https://github.com/kouphax/trello-cards/issues"&gt;complain&lt;/a&gt; and I'll fix it for you :) &lt;/p&gt;&lt;p&gt;Some other points worth noting,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Currently tested on Chrome 25 (OSX)&lt;/li&gt;
  &lt;li&gt;Could do with some basic tests around it&lt;/li&gt;
  &lt;li&gt;Currently no markdown support for descriptions&lt;/li&gt;
  &lt;li&gt;Story points use the &lt;a href="https://chrome.google.com/webstore/detail/jdbcdblgjdpmfninkoogcfpnkjmndgje?utm_source=chrome-ntp-icon"&gt;Trello Scrum Chrome Extension&lt;/a&gt; convention of &lt;code&gt;(POINTS)&lt;/code&gt; at the start of the card name/title. If you use that plugin then good for you, if not you can still make use of the points convention&lt;/li&gt;
  &lt;li&gt;Tasks are derived from the first checklist on the card&lt;/li&gt;
&lt;/ul&gt;</content></entry><entry><title>Agile Practices</title><updated>Sun Jul 08 00:00:00 UTC 2012</updated><author><name>James Hughes</name></author><link href="/presentations/agile-practices.pdf"></link><id>urn:yobriefca-se:feed:post:Agile Practices</id><content type="html"></content></entry><entry><title>Government Digital Service</title><updated>Mon Apr 02 00:00:00 UTC 2012</updated><author><name>James Hughes</name></author><link href="/presentations/gds.pdf"></link><id>urn:yobriefca-se:feed:post:Government Digital Service</id><content type="html"></content></entry></feed>